{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47070d7",
   "metadata": {},
   "source": [
    "# Model Evaluation: Comparing Forecasting Methods\n",
    "\n",
    "This notebook evaluates the performance of different forecasting models:\n",
    "- ARIMA\n",
    "- SARIMA (Seasonal ARIMA)\n",
    "- SARIMAX (Seasonal ARIMA with eXogenous variables)\n",
    "- Prophet\n",
    "- LSTM\n",
    "- TCN (Temporal Convolutional Network)\n",
    "- Transformer\n",
    "\n",
    "We'll use data from **10 randomly selected companies** and compare model accuracy using multiple metrics.\n",
    "\n",
    "## Model Input/Output Summary\n",
    "\n",
    "### Input Format\n",
    "All models accept the same input format:\n",
    "- **Input**: `pd.Series` - A time series of values (e.g., daily returns) with a datetime index\n",
    "- **Data Type**: Single univariate time series (one column of values over time)\n",
    "\n",
    "### Output Format\n",
    "All models return:\n",
    "- **Forecast**: `pd.Series` - Predicted values for future periods with datetime index\n",
    "- **Confidence Intervals**: `pd.Series` or `pd.DataFrame` (if available) - Upper and lower bounds\n",
    "\n",
    "### Model-Specific Details\n",
    "\n",
    "#### 1. ARIMA\n",
    "- **Input**: Univariate time series (pd.Series)\n",
    "- **Internal Processing**: Uses entire historical series to fit ARIMA model\n",
    "- **Output**: \n",
    "  - Forecast: `pd.Series` with future dates\n",
    "  - Confidence Intervals: `pd.DataFrame` with 'lower' and 'upper' columns\n",
    "\n",
    "#### 2. SARIMA\n",
    "- **Input**: Univariate time series (pd.Series)\n",
    "- **Internal Processing**: Uses entire historical series, captures seasonal patterns (e.g., weekly patterns)\n",
    "- **Output**: \n",
    "  - Forecast: `pd.Series` with future dates\n",
    "  - Confidence Intervals: `pd.DataFrame` with 'lower' and 'upper' columns\n",
    "\n",
    "#### 3. SARIMAX\n",
    "- **Input**: Univariate time series (pd.Series) + optional exogenous variables\n",
    "- **Internal Processing**: Uses historical series with additional features (rolling stats, lags)\n",
    "- **Output**: \n",
    "  - Forecast: `pd.Series` with future dates\n",
    "  - Confidence Intervals: `pd.DataFrame` with 'lower' and 'upper' columns\n",
    "\n",
    "#### 4. Prophet\n",
    "- **Input**: Univariate time series (pd.Series) - converts to DataFrame with 'ds' (dates) and 'y' (values)\n",
    "- **Internal Processing**: Uses entire historical series, handles seasonality\n",
    "- **Output**: \n",
    "  - Forecast: `pd.Series` with future dates\n",
    "  - Confidence Intervals: `pd.DataFrame` with 'lower' and 'upper' columns\n",
    "\n",
    "#### 5. LSTM\n",
    "- **Input**: Univariate time series (pd.Series)\n",
    "- **Internal Processing**: \n",
    "  - Creates sequences of `lookback_window` (default: 60) past values\n",
    "  - Normalizes data using MinMaxScaler\n",
    "  - Input shape: `(batch_size, lookback_window, 1)`\n",
    "- **Output**: \n",
    "  - Forecast: `pd.Series` with future dates\n",
    "  - Confidence Intervals: `None` (not available)\n",
    "\n",
    "#### 6. TCN\n",
    "- **Input**: Univariate time series (pd.Series)\n",
    "- **Internal Processing**: \n",
    "  - Creates sequences of `lookback_window` (default: 60) past values\n",
    "  - Normalizes data using MinMaxScaler\n",
    "  - Uses dilated convolutions with causal padding\n",
    "  - Input shape: `(batch_size, lookback_window, 1)`\n",
    "- **Output**: \n",
    "  - Forecast: `pd.Series` with future dates\n",
    "  - Confidence Intervals: `None` (not available)\n",
    "\n",
    "#### 7. Transformer\n",
    "- **Input**: Univariate time series (pd.Series)\n",
    "- **Internal Processing**: \n",
    "  - Creates sequences of `lookback_window` (default: 60) past values\n",
    "  - Normalizes data using MinMaxScaler\n",
    "  - Uses multi-head attention mechanism\n",
    "  - Input shape: `(batch_size, lookback_window, 1)`\n",
    "- **Output**: \n",
    "  - Forecast: `pd.Series` with future dates\n",
    "  - Confidence Intervals: `None` (not available)\n",
    "\n",
    "### Key Differences\n",
    "- **ARIMA, SARIMA, SARIMAX & Prophet**: Use entire historical series, provide confidence intervals\n",
    "- **LSTM, TCN, Transformer**: Use sliding windows of past values, no confidence intervals\n",
    "- **All models**: Return forecasts as `pd.Series` with datetime index matching the input frequency\n",
    "- **SARIMA**: Extends ARIMA with seasonal components (useful for weekly/monthly patterns)\n",
    "- **SARIMAX**: Extends SARIMA with exogenous variables (additional features like rolling statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 22:22:07.626447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765034527.644493  246409 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765034527.649835  246409 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1765034527.663472  246409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765034527.663491  246409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765034527.663492  246409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765034527.663494  246409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Project root: /home/dang.cpm/__MY_SPACE__/VinUni/FinLove\n",
      "Current directory: /home/dang.cpm/__MY_SPACE__/VinUni/FinLove/evaluation\n",
      "\n",
      "Note: If you encounter protobuf errors with TensorFlow models,\n",
      "try running: pip install protobuf==3.20.3\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import random\n",
    "\n",
    "# Fix for TensorFlow/protobuf compatibility issue\n",
    "# This error occurs when there's a version mismatch between TensorFlow and protobuf\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "# Suppress TensorFlow warnings and protobuf errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to fix protobuf issue by setting environment variable before importing TensorFlow\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    # Suppress the specific protobuf error\n",
    "    import logging\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Add project root to path\n",
    "# In Jupyter notebooks, Path.cwd() gives the current working directory\n",
    "# We assume the notebook is run from the project root or evaluation/ directory\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'evaluation':\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    # If running from project root, use current directory\n",
    "    project_root = current_dir\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import forecast functions\n",
    "from src.forecast import (\n",
    "    arima_forecast,\n",
    "    sarima_forecast,\n",
    "    sarimax_forecast,\n",
    "    prophet_forecast,\n",
    "    lstm_forecast,\n",
    "    tcn_forecast,\n",
    "    transformer_forecast\n",
    ")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "print(\"\\nNote: If you encounter protobuf errors with TensorFlow models,\")\n",
    "print(\"try running: pip install protobuf==3.20.3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943b7d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protobuf compatibility settings applied.\n",
      "If errors persist, restart kernel after running: pip install protobuf==3.20.3\n"
     ]
    }
   ],
   "source": [
    "# Fix protobuf compatibility issue\n",
    "# This cell fixes the common TensorFlow/protobuf version mismatch error\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def fix_protobuf():\n",
    "    \"\"\"Attempt to fix protobuf version compatibility.\"\"\"\n",
    "    try:\n",
    "        # Try to install compatible protobuf version\n",
    "        print(\"Attempting to fix protobuf compatibility...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"protobuf==3.20.3\"], \n",
    "                             stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(\"✓ Protobuf version fixed. Please restart the kernel and run all cells again.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Could not automatically fix protobuf. Please run manually:\")\n",
    "        print(f\"  pip install protobuf==3.20.3\")\n",
    "        print(f\"Or: pip install --upgrade protobuf\")\n",
    "        return False\n",
    "\n",
    "# Uncomment the line below if you're getting protobuf errors\n",
    "# fix_protobuf()\n",
    "\n",
    "# Alternative: Set environment variable to use Python implementation\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "print(\"Protobuf compatibility settings applied.\")\n",
    "print(\"If errors persist, restart kernel after running: pip install protobuf==3.20.3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32820307",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e839de3b",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data\n",
    "\n",
    "We'll randomly select 10 companies and load their data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0a1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 companies: ['MA', 'PG', 'XLK', 'NKE', 'XLB', 'HD', 'XLV', 'AAPL', 'AMZN', 'XLY']\n",
      "Total files available: 29\n",
      "\n",
      "MA:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $76.10 - $598.17\n",
      "\n",
      "PG:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $56.85 - $175.07\n",
      "\n",
      "XLK:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $34.66 - $304.13\n",
      "\n",
      "NKE:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $44.32 - $167.31\n",
      "\n",
      "XLB:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $30.68 - $95.72\n",
      "\n",
      "HD:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $88.72 - $423.60\n",
      "\n",
      "XLV:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $54.01 - $154.61\n",
      "\n",
      "AAPL:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $20.60 - $275.25\n",
      "\n",
      "AMZN:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $24.10 - $254.00\n",
      "\n",
      "XLY:\n",
      "  Data points: 2512\n",
      "  Date range: 2015-11-27 00:00:00 to 2025-11-21 00:00:00\n",
      "  Price range: $61.66 - $242.18\n"
     ]
    }
   ],
   "source": [
    "# Define data directory\n",
    "data_dir = project_root / 'data'\n",
    "\n",
    "# Get all CSV files (excluding cache directory)\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Randomly select 10 companies\n",
    "random.seed(42)  # For reproducibility\n",
    "num_companies = min(10, len(csv_files))  # Use 10 or all available if less than 10\n",
    "selected_companies = random.sample(csv_files, num_companies)\n",
    "\n",
    "print(f\"Selected {num_companies} companies: {[f.split('_')[0] for f in selected_companies]}\")\n",
    "print(f\"Total files available: {len(csv_files)}\")\n",
    "\n",
    "def load_company_data(filepath: Path) -> Tuple[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    Load company data from CSV file.\n",
    "    \n",
    "    The CSV structure is:\n",
    "    - Row 1: Column names (Price, Close, High, Low, Open, Volume)\n",
    "    - Row 2: Ticker metadata\n",
    "    - Row 3: Date header row\n",
    "    - Row 4+: Actual data with dates in first column\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (ticker, Series with Date index and Close prices)\n",
    "    \"\"\"\n",
    "    # Read CSV with header from first row, skip rows 2 and 3 (ticker and Date header)\n",
    "    df = pd.read_csv(filepath, header=0, skiprows=[1, 2])\n",
    "    \n",
    "    # Extract ticker from filename\n",
    "    ticker = filepath.stem.split('_')[0]\n",
    "    \n",
    "    # The first column should be 'Price' which contains the dates\n",
    "    # Rename it to 'Date' for clarity\n",
    "    if 'Price' in df.columns:\n",
    "        df = df.rename(columns={'Price': 'Date'})\n",
    "    \n",
    "    # Convert Date column to datetime and set as index\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Use Close price column\n",
    "    if 'Close' not in df.columns:\n",
    "        # If Close column doesn't exist, check what columns we have\n",
    "        raise ValueError(f\"Close column not found. Available columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    close_prices = df['Close'].copy()\n",
    "    \n",
    "    return ticker, close_prices\n",
    "\n",
    "# Load data for both companies\n",
    "company_data = {}\n",
    "for filename in selected_companies:\n",
    "    filepath = data_dir / filename\n",
    "    ticker, prices = load_company_data(filepath)\n",
    "    company_data[ticker] = prices\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"  Data points: {len(prices)}\")\n",
    "    print(f\"  Date range: {prices.index[0]} to {prices.index[-1]}\")\n",
    "    print(f\"  Price range: ${prices.min():.2f} - ${prices.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf432ebb",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Returns and Split Data\n",
    "\n",
    "We'll calculate daily returns and split the data into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661e0ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MA Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000844\n",
      "  Std return: 0.016934\n",
      "  Min return: -0.127254\n",
      "  Max return: 0.166109\n",
      "\n",
      "PG Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000454\n",
      "  Std return: 0.011794\n",
      "  Min return: -0.087373\n",
      "  Max return: 0.120090\n",
      "\n",
      "XLK Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000891\n",
      "  Std return: 0.015279\n",
      "  Min return: -0.138140\n",
      "  Max return: 0.134257\n",
      "\n",
      "NKE Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000220\n",
      "  Std return: 0.019837\n",
      "  Min return: -0.199809\n",
      "  Max return: 0.155315\n",
      "\n",
      "XLB Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000421\n",
      "  Std return: 0.013125\n",
      "  Min return: -0.110084\n",
      "  Max return: 0.117601\n",
      "\n",
      "HD Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000588\n",
      "  Std return: 0.015489\n",
      "  Min return: -0.197938\n",
      "  Max return: 0.137508\n",
      "\n",
      "XLV Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000426\n",
      "  Std return: 0.010513\n",
      "  Min return: -0.098610\n",
      "  Max return: 0.077057\n",
      "\n",
      "AAPL Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.001094\n",
      "  Std return: 0.018354\n",
      "  Min return: -0.128647\n",
      "  Max return: 0.153289\n",
      "\n",
      "AMZN Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000963\n",
      "  Std return: 0.020724\n",
      "  Min return: -0.140494\n",
      "  Max return: 0.135359\n",
      "\n",
      "XLY Returns:\n",
      "  Data points: 2511\n",
      "  Mean return: 0.000546\n",
      "  Std return: 0.013855\n",
      "  Min return: -0.126686\n",
      "  Max return: 0.108881\n",
      "\n",
      "MA Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "PG Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "XLK Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "NKE Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "XLB Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "HD Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "XLV Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "AAPL Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "AMZN Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n",
      "\n",
      "XLY Split:\n",
      "  Train: 2008 points (2015-11-30 00:00:00 to 2023-11-20 00:00:00)\n",
      "  Test: 503 points (2023-11-21 00:00:00 to 2025-11-21 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "# Calculate returns for each company\n",
    "# Returns = (Price_t - Price_{t-1}) / Price_{t-1}\n",
    "returns_data = {}\n",
    "for ticker, prices in company_data.items():\n",
    "    returns = prices.pct_change().dropna()\n",
    "    returns_data[ticker] = returns\n",
    "    print(f\"\\n{ticker} Returns:\")\n",
    "    print(f\"  Data points: {len(returns)}\")\n",
    "    print(f\"  Mean return: {returns.mean():.6f}\")\n",
    "    print(f\"  Std return: {returns.std():.6f}\")\n",
    "    print(f\"  Min return: {returns.min():.6f}\")\n",
    "    print(f\"  Max return: {returns.max():.6f}\")\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Use 80% for training, 20% for testing\n",
    "train_test_split = {}\n",
    "for ticker, returns in returns_data.items():\n",
    "    split_idx = int(len(returns) * 0.8)\n",
    "    train_returns = returns.iloc[:split_idx]\n",
    "    test_returns = returns.iloc[split_idx:]\n",
    "    \n",
    "    train_test_split[ticker] = {\n",
    "        'train': train_returns,\n",
    "        'test': test_returns\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{ticker} Split:\")\n",
    "    print(f\"  Train: {len(train_returns)} points ({train_returns.index[0]} to {train_returns.index[-1]})\")\n",
    "    print(f\"  Test: {len(test_returns)} points ({test_returns.index[0]} to {test_returns.index[-1]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3969a17",
   "metadata": {},
   "source": [
    "## Step 3: Define Evaluation Metrics\n",
    "\n",
    "We'll calculate multiple metrics to compare model performance:\n",
    "- MAE (Mean Absolute Error)\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- MAPE (Mean Absolute Percentage Error)\n",
    "- R² (Coefficient of Determination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88886075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics function defined!\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(y_true: pd.Series, y_pred: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics for forecast predictions.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True values\n",
    "        y_pred: Predicted values\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with metric names and values\n",
    "    \"\"\"\n",
    "    # Align indices in case they don't match exactly\n",
    "    common_idx = y_true.index.intersection(y_pred.index)\n",
    "    if len(common_idx) == 0:\n",
    "        # If no common index, use positional alignment\n",
    "        min_len = min(len(y_true), len(y_pred))\n",
    "        y_true_aligned = y_true.iloc[:min_len].values\n",
    "        y_pred_aligned = y_pred.iloc[:min_len].values\n",
    "    else:\n",
    "        y_true_aligned = y_true.loc[common_idx].values\n",
    "        y_pred_aligned = y_pred.loc[common_idx].values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(y_true_aligned - y_pred_aligned))\n",
    "    rmse = np.sqrt(np.mean((y_true_aligned - y_pred_aligned) ** 2))\n",
    "    \n",
    "    # MAPE - handle division by zero\n",
    "    mask = np.abs(y_true_aligned) > 1e-10\n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((y_true_aligned[mask] - y_pred_aligned[mask]) / y_true_aligned[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    \n",
    "    # R² score\n",
    "    ss_res = np.sum((y_true_aligned - y_pred_aligned) ** 2)\n",
    "    ss_tot = np.sum((y_true_aligned - np.mean(y_true_aligned)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R²': r2\n",
    "    }\n",
    "\n",
    "print(\"Evaluation metrics function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d783d1",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Models\n",
    "\n",
    "We'll evaluate each model on all 10 companies and collect the results.\n",
    "\n",
    "**Note**: This may take a while as we're evaluating 7 models × 10 companies = 70 model runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating models for MA (1/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.006683, RMSE: 0.008497\n",
      "\n",
      "[2/5] Prophet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:22:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:22:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Prophet completed - MAE: 0.006624, RMSE: 0.008486\n",
      "\n",
      "[3/5] LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765034541.081670  246409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21795 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
      "I0000 00:00:1765034541.083566  246409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11529 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "I0000 00:00:1765034541.091742  246409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22355 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3d:00.0, compute capability: 8.6\n",
      "I0000 00:00:1765034541.099324  246409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10247 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3e:00.0, compute capability: 8.6\n",
      "I0000 00:00:1765034541.101709  246409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 22355 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:88:00.0, compute capability: 8.6\n",
      "I0000 00:00:1765034541.103703  246409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 1153 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:89:00.0, compute capability: 8.6\n",
      "I0000 00:00:1765034541.105843  246409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 3107 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b1:00.0, compute capability: 8.6\n",
      "I0000 00:00:1765034541.108535  246409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 3131 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b2:00.0, compute capability: 8.6\n",
      "I0000 00:00:1765034542.794420  247853 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ LSTM completed - MAE: 0.007102, RMSE: 0.008642\n",
      "\n",
      "[4/5] TCN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765034548.332813  247853 service.cc:152] XLA service 0x7f1fd906d110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1765034548.332865  247853 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1765034548.332877  247853 service.cc:160]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1765034548.332881  247853 service.cc:160]   StreamExecutor device (2): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1765034548.332884  247853 service.cc:160]   StreamExecutor device (3): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1765034548.332890  247853 service.cc:160]   StreamExecutor device (4): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1765034548.332896  247853 service.cc:160]   StreamExecutor device (5): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1765034548.332899  247853 service.cc:160]   StreamExecutor device (6): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1765034548.332903  247853 service.cc:160]   StreamExecutor device (7): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1765034548.982067  247853 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ TCN completed - MAE: 0.006476, RMSE: 0.008317\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.006461, RMSE: 0.008569\n",
      "\n",
      "MA evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for PG (2/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:22:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:22:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.009129, RMSE: 0.012760\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.009124, RMSE: 0.012779\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.008949, RMSE: 0.012631\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.008900, RMSE: 0.012494\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.013467, RMSE: 0.016978\n",
      "\n",
      "PG evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for XLK (3/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:23:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:23:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.006228, RMSE: 0.007676\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.005525, RMSE: 0.007089\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.007008, RMSE: 0.008071\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.006258, RMSE: 0.007436\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.013014, RMSE: 0.014397\n",
      "\n",
      "XLK evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for NKE (4/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:23:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:23:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.009150, RMSE: 0.011840\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.009150, RMSE: 0.012131\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.010015, RMSE: 0.012918\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.008234, RMSE: 0.010792\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.008082, RMSE: 0.010245\n",
      "\n",
      "NKE evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for XLB (5/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:24:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:24:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.006788, RMSE: 0.008374\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.006770, RMSE: 0.008461\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.006076, RMSE: 0.008272\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.007991, RMSE: 0.009349\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.006627, RMSE: 0.009083\n",
      "\n",
      "XLB evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for HD (6/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:24:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:24:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.009244, RMSE: 0.011964\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.008997, RMSE: 0.012016\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.008523, RMSE: 0.011205\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.009948, RMSE: 0.012831\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.008603, RMSE: 0.011316\n",
      "\n",
      "HD evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for XLV (7/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:25:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:25:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.005441, RMSE: 0.007148\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.005468, RMSE: 0.007191\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.006227, RMSE: 0.007765\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.005518, RMSE: 0.007128\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.006103, RMSE: 0.008060\n",
      "\n",
      "XLV evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for AAPL (8/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:25:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:25:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.007262, RMSE: 0.008755\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.007709, RMSE: 0.009109\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.007368, RMSE: 0.008866\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.007457, RMSE: 0.008829\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.008171, RMSE: 0.009938\n",
      "\n",
      "AAPL evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for AMZN (9/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:26:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:26:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.010575, RMSE: 0.012368\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.011027, RMSE: 0.012704\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.010725, RMSE: 0.012437\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.010545, RMSE: 0.012409\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.011245, RMSE: 0.013293\n",
      "\n",
      "AMZN evaluation completed!\n",
      "\n",
      "============================================================\n",
      "Evaluating models for XLY (10/10)\n",
      "============================================================\n",
      "\n",
      "[1/5] ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:26:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:26:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ ARIMA completed - MAE: 0.005357, RMSE: 0.007260\n",
      "\n",
      "[2/5] Prophet...\n",
      "  ✓ Prophet completed - MAE: 0.005385, RMSE: 0.007413\n",
      "\n",
      "[3/5] LSTM...\n",
      "  ✓ LSTM completed - MAE: 0.004910, RMSE: 0.006910\n",
      "\n",
      "[4/5] TCN...\n",
      "  ✓ TCN completed - MAE: 0.005043, RMSE: 0.006978\n",
      "\n",
      "[5/5] Transformer...\n",
      "  ✓ Transformer completed - MAE: 0.006663, RMSE: 0.008359\n",
      "\n",
      "XLY evaluation completed!\n",
      "\n",
      "============================================================\n",
      "All evaluations completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define forecast horizon (number of days to predict)\n",
    "forecast_horizon = 30\n",
    "\n",
    "# Store results for each company and model\n",
    "results = {}\n",
    "\n",
    "# Track progress\n",
    "total_companies = len(train_test_split)\n",
    "company_num = 0\n",
    "\n",
    "# Evaluate each company\n",
    "for ticker, data in train_test_split.items():\n",
    "    company_num += 1\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating models for {ticker} ({company_num}/{total_companies})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    train_returns = data['train']\n",
    "    test_returns = data['test']\n",
    "    \n",
    "    # Limit test set to forecast_horizon for fair comparison\n",
    "    actual_test = test_returns.iloc[:forecast_horizon]\n",
    "    \n",
    "    results[ticker] = {}\n",
    "    \n",
    "    # 1. ARIMA\n",
    "    print(f\"\\n[1/7] ARIMA...\")\n",
    "    try:\n",
    "        forecast, _ = arima_forecast(\n",
    "            train_returns,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            auto_select=True\n",
    "        )\n",
    "        metrics = calculate_metrics(actual_test, forecast)\n",
    "        results[ticker]['ARIMA'] = metrics\n",
    "        print(f\"  ✓ ARIMA completed - MAE: {metrics['MAE']:.6f}, RMSE: {metrics['RMSE']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ ARIMA failed: {str(e)}\")\n",
    "        results[ticker]['ARIMA'] = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'R²': np.nan}\n",
    "    \n",
    "    # 2. SARIMA\n",
    "    print(f\"\\n[2/7] SARIMA...\")\n",
    "    try:\n",
    "        forecast, _ = sarima_forecast(\n",
    "            train_returns,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            auto_select=True\n",
    "        )\n",
    "        metrics = calculate_metrics(actual_test, forecast)\n",
    "        results[ticker]['SARIMA'] = metrics\n",
    "        print(f\"  ✓ SARIMA completed - MAE: {metrics['MAE']:.6f}, RMSE: {metrics['RMSE']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ SARIMA failed: {str(e)}\")\n",
    "        results[ticker]['SARIMA'] = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'R²': np.nan}\n",
    "    \n",
    "    # 3. SARIMAX\n",
    "    print(f\"\\n[3/7] SARIMAX...\")\n",
    "    try:\n",
    "        forecast, _ = sarimax_forecast(\n",
    "            train_returns,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            auto_select=True\n",
    "        )\n",
    "        metrics = calculate_metrics(actual_test, forecast)\n",
    "        results[ticker]['SARIMAX'] = metrics\n",
    "        print(f\"  ✓ SARIMAX completed - MAE: {metrics['MAE']:.6f}, RMSE: {metrics['RMSE']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ SARIMAX failed: {str(e)}\")\n",
    "        results[ticker]['SARIMAX'] = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'R²': np.nan}\n",
    "    \n",
    "    # 4. Prophet\n",
    "    print(f\"\\n[4/7] Prophet...\")\n",
    "    try:\n",
    "        forecast, _ = prophet_forecast(\n",
    "            train_returns,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            yearly_seasonality=False,  # Disable for daily returns\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False\n",
    "        )\n",
    "        metrics = calculate_metrics(actual_test, forecast)\n",
    "        results[ticker]['Prophet'] = metrics\n",
    "        print(f\"  ✓ Prophet completed - MAE: {metrics['MAE']:.6f}, RMSE: {metrics['RMSE']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Prophet failed: {str(e)}\")\n",
    "        results[ticker]['Prophet'] = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'R²': np.nan}\n",
    "    \n",
    "    # 5. LSTM\n",
    "    print(f\"\\n[5/7] LSTM...\")\n",
    "    try:\n",
    "        forecast, _ = lstm_forecast(\n",
    "            train_returns,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            lookback_window=60,\n",
    "            lstm_units=50,\n",
    "            epochs=20,  # Reduced for faster evaluation\n",
    "            batch_size=32,\n",
    "            use_cache=True,\n",
    "            ticker=ticker\n",
    "        )\n",
    "        metrics = calculate_metrics(actual_test, forecast)\n",
    "        results[ticker]['LSTM'] = metrics\n",
    "        print(f\"  ✓ LSTM completed - MAE: {metrics['MAE']:.6f}, RMSE: {metrics['RMSE']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ LSTM failed: {str(e)}\")\n",
    "        results[ticker]['LSTM'] = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'R²': np.nan}\n",
    "    \n",
    "    # 6. TCN\n",
    "    print(f\"\\n[6/7] TCN...\")\n",
    "    try:\n",
    "        forecast, _ = tcn_forecast(\n",
    "            train_returns,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            lookback_window=60,\n",
    "            num_filters=64,\n",
    "            kernel_size=3,\n",
    "            num_blocks=2,\n",
    "            epochs=20,  # Reduced for faster evaluation\n",
    "            batch_size=32,\n",
    "            use_cache=True,\n",
    "            ticker=ticker\n",
    "        )\n",
    "        metrics = calculate_metrics(actual_test, forecast)\n",
    "        results[ticker]['TCN'] = metrics\n",
    "        print(f\"  ✓ TCN completed - MAE: {metrics['MAE']:.6f}, RMSE: {metrics['RMSE']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ TCN failed: {str(e)}\")\n",
    "        results[ticker]['TCN'] = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'R²': np.nan}\n",
    "    \n",
    "    # 7. Transformer\n",
    "    print(f\"\\n[7/7] Transformer...\")\n",
    "    try:\n",
    "        forecast, _ = transformer_forecast(\n",
    "            train_returns,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            lookback_window=60,\n",
    "            d_model=64,\n",
    "            num_heads=4,\n",
    "            num_layers=2,\n",
    "            epochs=20,  # Reduced for faster evaluation\n",
    "            batch_size=32,\n",
    "            use_cache=True,\n",
    "            ticker=ticker\n",
    "        )\n",
    "        metrics = calculate_metrics(actual_test, forecast)\n",
    "        results[ticker]['Transformer'] = metrics\n",
    "        print(f\"  ✓ Transformer completed - MAE: {metrics['MAE']:.6f}, RMSE: {metrics['RMSE']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Transformer failed: {str(e)}\")\n",
    "        results[ticker]['Transformer'] = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'R²': np.nan}\n",
    "    \n",
    "    print(f\"\\n{ticker} evaluation completed!\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All evaluations completed!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fedbe45",
   "metadata": {},
   "source": [
    "## Step 5: Create Comparison Table\n",
    "\n",
    "Now we'll create a comprehensive comparison table showing all metrics for all models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16261707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "================================================================================\n",
      "\n",
      "Detailed Results:\n",
      "Company       Model      MAE     RMSE        MAPE        R²\n",
      "     MA       ARIMA 0.006683 0.008497  285.311476 -0.023658\n",
      "     MA     Prophet 0.006624 0.008486  258.490351 -0.021104\n",
      "     MA        LSTM 0.007102 0.008642  243.770144 -0.058927\n",
      "     MA         TCN 0.006476 0.008317  335.668377  0.019103\n",
      "     MA Transformer 0.006461 0.008569  933.402334 -0.041172\n",
      "     PG       ARIMA 0.009129 0.012760  106.868276 -0.042332\n",
      "     PG     Prophet 0.009124 0.012779   99.892855 -0.045343\n",
      "     PG        LSTM 0.008949 0.012631   98.241673 -0.021267\n",
      "     PG         TCN 0.008900 0.012494   98.771720  0.000666\n",
      "     PG Transformer 0.013467 0.016978  361.687983 -0.845194\n",
      "    XLK       ARIMA 0.006228 0.007676  289.423485 -0.204227\n",
      "    XLK     Prophet 0.005525 0.007089  184.269196 -0.027288\n",
      "    XLK        LSTM 0.007008 0.008071  254.715218 -0.331321\n",
      "    XLK         TCN 0.006258 0.007436  269.790942 -0.130300\n",
      "    XLK Transformer 0.013014 0.014397 1365.662708 -3.236404\n",
      "    NKE       ARIMA 0.009150 0.011840  100.888860 -0.363466\n",
      "    NKE     Prophet 0.009150 0.012131   89.146161 -0.431153\n",
      "    NKE        LSTM 0.010015 0.012918  104.432790 -0.622889\n",
      "    NKE         TCN 0.008234 0.010792  110.541207 -0.132792\n",
      "    NKE Transformer 0.008082 0.010245  190.970726 -0.020874\n",
      "    XLB       ARIMA 0.006788 0.008374   93.528980 -0.066949\n",
      "    XLB     Prophet 0.006770 0.008461   92.969304 -0.089124\n",
      "    XLB        LSTM 0.006076 0.008272  129.969042 -0.040960\n",
      "    XLB         TCN 0.007991 0.009349  129.654214 -0.329816\n",
      "    XLB Transformer 0.006627 0.009083  183.997049 -0.255008\n",
      "     HD       ARIMA 0.009244 0.011964  118.375254 -0.349965\n",
      "     HD     Prophet 0.008997 0.012016   97.450957 -0.361743\n",
      "     HD        LSTM 0.008523 0.011205  152.258420 -0.184146\n",
      "     HD         TCN 0.009948 0.012831  158.206279 -0.552758\n",
      "     HD Transformer 0.008603 0.011316  136.173624 -0.207801\n",
      "    XLV       ARIMA 0.005441 0.007148   92.597677 -0.032222\n",
      "    XLV     Prophet 0.005468 0.007191   94.629534 -0.044710\n",
      "    XLV        LSTM 0.006227 0.007765  152.640262 -0.218205\n",
      "    XLV         TCN 0.005518 0.007128  102.812362 -0.026594\n",
      "    XLV Transformer 0.006103 0.008060  249.134185 -0.312421\n",
      "   AAPL       ARIMA 0.007262 0.008755  101.478554  0.003182\n",
      "   AAPL     Prophet 0.007709 0.009109  119.576919 -0.079032\n",
      "   AAPL        LSTM 0.007368 0.008866  104.458066 -0.022274\n",
      "   AAPL         TCN 0.007457 0.008829  101.929630 -0.013599\n",
      "   AAPL Transformer 0.008171 0.009938  167.775716 -0.284389\n",
      "   AMZN       ARIMA 0.010575 0.012368  117.229842 -0.005346\n",
      "   AMZN     Prophet 0.011027 0.012704  151.144961 -0.060707\n",
      "   AMZN        LSTM 0.010725 0.012437  193.929483 -0.016651\n",
      "   AMZN         TCN 0.010545 0.012409  109.256631 -0.012023\n",
      "   AMZN Transformer 0.011245 0.013293  295.850292 -0.161347\n",
      "    XLY       ARIMA 0.005357 0.007260   90.858394 -0.120828\n",
      "    XLY     Prophet 0.005385 0.007413   88.918491 -0.168484\n",
      "    XLY        LSTM 0.004910 0.006910  108.357309 -0.015229\n",
      "    XLY         TCN 0.005043 0.006978  120.201255 -0.035408\n",
      "    XLY Transformer 0.006663 0.008359  136.186260 -0.485733\n",
      "\n",
      "================================================================================\n",
      "AVERAGE METRICS ACROSS ALL COMPANIES\n",
      "================================================================================\n",
      "\n",
      "Summary Statistics:\n",
      "      Model  MAE (avg)  RMSE (avg)  MAPE (avg)  R² (avg)  MAE (std)  RMSE (std)\n",
      "      ARIMA   0.007586    0.009664  139.656080 -0.120581   0.001810    0.002281\n",
      "    Prophet   0.007578    0.009738  127.648873 -0.132869   0.001939    0.002391\n",
      "       LSTM   0.007690    0.009772  154.277241 -0.153187   0.001834    0.002278\n",
      "        TCN   0.007637    0.009656  153.683262 -0.121352   0.001837    0.002311\n",
      "Transformer   0.008844    0.011024  402.084088 -0.585034   0.002758    0.002973\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive results table\n",
    "all_results = []\n",
    "\n",
    "# Collect results for each company and model\n",
    "for ticker, model_results in results.items():\n",
    "    for model_name, metrics in model_results.items():\n",
    "        all_results.append({\n",
    "            'Company': ticker,\n",
    "            'Model': model_name,\n",
    "            'MAE': metrics['MAE'],\n",
    "            'RMSE': metrics['RMSE'],\n",
    "            'MAPE': metrics['MAPE'],\n",
    "            'R²': metrics['R²']\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Display the results table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Create a summary table with averages across companies\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGE METRICS ACROSS ALL COMPANIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for model in ['ARIMA', 'SARIMA', 'SARIMAX', 'Prophet', 'LSTM', 'TCN', 'Transformer']:\n",
    "    model_data = results_df[results_df['Model'] == model]\n",
    "    if len(model_data) > 0:\n",
    "        summary_data.append({\n",
    "            'Model': model,\n",
    "            'MAE (avg)': model_data['MAE'].mean(),\n",
    "            'RMSE (avg)': model_data['RMSE'].mean(),\n",
    "            'MAPE (avg)': model_data['MAPE'].mean(),\n",
    "            'R² (avg)': model_data['R²'].mean(),\n",
    "            'MAE (std)': model_data['MAE'].std(),\n",
    "            'RMSE (std)': model_data['RMSE'].std()\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4a729",
   "metadata": {},
   "source": [
    "## Step 6: Formatted Comparison Table\n",
    "\n",
    "A nicely formatted table for easy comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521a3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MAE (Mean Absolute Error) - Lower is Better\n",
      "================================================================================\n",
      "Model       ARIMA      LSTM   Prophet       TCN  Transformer\n",
      "Company                                                     \n",
      "AAPL     0.007262  0.007368  0.007709  0.007457     0.008171\n",
      "AMZN     0.010575  0.010725  0.011027  0.010545     0.011245\n",
      "HD       0.009244  0.008523  0.008997  0.009948     0.008603\n",
      "MA       0.006683  0.007102  0.006624  0.006476     0.006461\n",
      "NKE      0.009150  0.010015  0.009150  0.008234     0.008082\n",
      "PG       0.009129  0.008949  0.009124  0.008900     0.013467\n",
      "XLB      0.006788  0.006076  0.006770  0.007991     0.006627\n",
      "XLK      0.006228  0.007008  0.005525  0.006258     0.013014\n",
      "XLV      0.005441  0.006227  0.005468  0.005518     0.006103\n",
      "XLY      0.005357  0.004910  0.005385  0.005043     0.006663\n",
      "\n",
      "================================================================================\n",
      "RMSE (Root Mean Squared Error) - Lower is Better\n",
      "================================================================================\n",
      "Model       ARIMA      LSTM   Prophet       TCN  Transformer\n",
      "Company                                                     \n",
      "AAPL     0.008755  0.008866  0.009109  0.008829     0.009938\n",
      "AMZN     0.012368  0.012437  0.012704  0.012409     0.013293\n",
      "HD       0.011964  0.011205  0.012016  0.012831     0.011316\n",
      "MA       0.008497  0.008642  0.008486  0.008317     0.008569\n",
      "NKE      0.011840  0.012918  0.012131  0.010792     0.010245\n",
      "PG       0.012760  0.012631  0.012779  0.012494     0.016978\n",
      "XLB      0.008374  0.008272  0.008461  0.009349     0.009083\n",
      "XLK      0.007676  0.008071  0.007089  0.007436     0.014397\n",
      "XLV      0.007148  0.007765  0.007191  0.007128     0.008060\n",
      "XLY      0.007260  0.006910  0.007413  0.006978     0.008359\n",
      "\n",
      "================================================================================\n",
      "R² (Coefficient of Determination) - Higher is Better (closer to 1)\n",
      "================================================================================\n",
      "Model     ARIMA    LSTM  Prophet     TCN  Transformer\n",
      "Company                                              \n",
      "AAPL     0.0032 -0.0223  -0.0790 -0.0136      -0.2844\n",
      "AMZN    -0.0053 -0.0167  -0.0607 -0.0120      -0.1613\n",
      "HD      -0.3500 -0.1841  -0.3617 -0.5528      -0.2078\n",
      "MA      -0.0237 -0.0589  -0.0211  0.0191      -0.0412\n",
      "NKE     -0.3635 -0.6229  -0.4312 -0.1328      -0.0209\n",
      "PG      -0.0423 -0.0213  -0.0453  0.0007      -0.8452\n",
      "XLB     -0.0669 -0.0410  -0.0891 -0.3298      -0.2550\n",
      "XLK     -0.2042 -0.3313  -0.0273 -0.1303      -3.2364\n",
      "XLV     -0.0322 -0.2182  -0.0447 -0.0266      -0.3124\n",
      "XLY     -0.1208 -0.0152  -0.1685 -0.0354      -0.4857\n",
      "\n",
      "================================================================================\n",
      "BEST MODEL FOR EACH METRIC (across all companies)\n",
      "================================================================================\n",
      "\n",
      "Best MAE:  Prophet (0.007578)\n",
      "Best RMSE: TCN (0.009656)\n",
      "Best R²:   ARIMA (-0.1206)\n",
      "\n",
      "================================================================================\n",
      "OVERALL RANKING (lower rank is better)\n",
      "================================================================================\n",
      "                  MAE      RMSE        R²  Overall_Rank\n",
      "Model                                                  \n",
      "ARIMA        0.007586  0.009664 -0.120581      1.666667\n",
      "TCN          0.007637  0.009656 -0.121352      2.000000\n",
      "Prophet      0.007578  0.009738 -0.132869      2.333333\n",
      "LSTM         0.007690  0.009772 -0.153187      4.000000\n",
      "Transformer  0.008844  0.011024 -0.585034      5.000000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a pivot table for better visualization\n",
    "pivot_mae = results_df.pivot(index='Company', columns='Model', values='MAE')\n",
    "pivot_rmse = results_df.pivot(index='Company', columns='Model', values='RMSE')\n",
    "pivot_r2 = results_df.pivot(index='Company', columns='Model', values='R²')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAE (Mean Absolute Error) - Lower is Better\")\n",
    "print(\"=\"*80)\n",
    "print(pivot_mae.round(6).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RMSE (Root Mean Squared Error) - Lower is Better\")\n",
    "print(\"=\"*80)\n",
    "print(pivot_rmse.round(6).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"R² (Coefficient of Determination) - Higher is Better (closer to 1)\")\n",
    "print(\"=\"*80)\n",
    "print(pivot_r2.round(4).to_string())\n",
    "\n",
    "# Find best model for each metric\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL FOR EACH METRIC (across all companies)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_metrics = results_df.groupby('Model').agg({\n",
    "    'MAE': 'mean',\n",
    "    'RMSE': 'mean',\n",
    "    'R²': 'mean'\n",
    "}).round(6)\n",
    "\n",
    "best_mae = avg_metrics['MAE'].idxmin()\n",
    "best_rmse = avg_metrics['RMSE'].idxmin()\n",
    "best_r2 = avg_metrics['R²'].idxmax()\n",
    "\n",
    "print(f\"\\nBest MAE:  {best_mae} ({avg_metrics.loc[best_mae, 'MAE']:.6f})\")\n",
    "print(f\"Best RMSE: {best_rmse} ({avg_metrics.loc[best_rmse, 'RMSE']:.6f})\")\n",
    "print(f\"Best R²:   {best_r2} ({avg_metrics.loc[best_r2, 'R²']:.4f})\")\n",
    "\n",
    "# Overall ranking (based on average rank across all metrics)\n",
    "avg_metrics['MAE_rank'] = avg_metrics['MAE'].rank()\n",
    "avg_metrics['RMSE_rank'] = avg_metrics['RMSE'].rank()\n",
    "avg_metrics['R²_rank'] = avg_metrics['R²'].rank(ascending=False)  # Higher is better\n",
    "avg_metrics['Overall_Rank'] = (avg_metrics['MAE_rank'] + avg_metrics['RMSE_rank'] + avg_metrics['R²_rank']) / 3\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL RANKING (lower rank is better)\")\n",
    "print(\"=\"*80)\n",
    "ranking = avg_metrics[['MAE', 'RMSE', 'R²', 'Overall_Rank']].sort_values('Overall_Rank')\n",
    "print(ranking.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12560a70",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This evaluation compares the performance of 7 forecasting models:\n",
    "- **ARIMA**: Statistical time series model\n",
    "- **SARIMA**: Seasonal ARIMA model (captures seasonal patterns)\n",
    "- **SARIMAX**: Seasonal ARIMA with exogenous variables (uses additional features)\n",
    "- **Prophet**: Facebook's forecasting tool\n",
    "- **LSTM**: Long Short-Term Memory neural network\n",
    "- **TCN**: Temporal Convolutional Network\n",
    "- **Transformer**: Attention-based neural network\n",
    "\n",
    "### Metrics Explained:\n",
    "- **MAE (Mean Absolute Error)**: Average absolute difference between predicted and actual values. Lower is better.\n",
    "- **RMSE (Root Mean Squared Error)**: Square root of average squared differences. Penalizes large errors more. Lower is better.\n",
    "- **MAPE (Mean Absolute Percentage Error)**: Average percentage error. Lower is better.\n",
    "- **R² (Coefficient of Determination)**: Proportion of variance explained. Closer to 1 is better.\n",
    "\n",
    "The models are evaluated on daily returns data, which is more challenging to predict than prices due to the noisy nature of financial returns.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
